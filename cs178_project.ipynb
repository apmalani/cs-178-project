{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0a48e8",
   "metadata": {},
   "source": [
    "## CS 178 Project Code\n",
    "\n",
    "### Arun Malani, Brock Allan, Nathan Chau\n",
    "\n",
    "Includes data analysis, model training, performance charts, model fine-tuning, and brief explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fefcb3a-cffb-4f13-ac56-c554676cb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all we need to import the data that we are using, specifically the IMDB Review / Large Movie Review Dataset\n",
    "#Dataset\tType\t#Instances\t#Labels\t   Each Instance\t\n",
    "#NLP\t                50K    \t   2\t    Movie review\n",
    "\n",
    "#The dataset provides a set of 25,000 highly polar movie reviews for training, and 25,000 for testing, there is also unlabeled data - unsupervised?\n",
    "#States that Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details.\n",
    "#Information gained from the readme is as follows:\n",
    "#25k positive and 25k negative reviews\n",
    "#50k unlabeled reviews for unsupervised learning\n",
    "#each movie has at most 30 reviews - since reviews for the same movie tend to have the same correlation\n",
    "#train and test sets are disjoint, so no significant performance by memorizing movie unique terms\n",
    "#negative reviews are those with a score <= 4 out of 10\n",
    "#positive reviews are those with a score >= 7 out of 10\n",
    "#labeled data sets do NOT have the neutral reviews 5-6 but unlabeled data sets DO\n",
    "#unsupervised learning therefore will want to have k = 3 clusters for each\n",
    "#states that for unlabeled data there are an even number of reviews > 5 and <= 5\n",
    "\n",
    "#contains the following file folders, train and test.\n",
    "#inside of these folders are a positive and negative folder\n",
    "#inside are reviews stored in text files named as follows:\n",
    "#`[[id]_[rating].txt]` where the id is a unique id and rating is the star rating for that review on a scale of 1-10.\n",
    "#for example: `[test/pos/200_8.txt]` is the text for a positive labeled test with id 200 and a rating of 8/10\n",
    "#the unlabeled set is in train and has a 0 for all ratings\n",
    "#the data includes the url for each review where the ID is actually the line in the file in which it occurs\n",
    "#for example: `[urls_[pos, neg, unsup].txt]` where ID 200 means line 200, the url however just goes to the movies review page\n",
    "\n",
    "#the already tokenized bag of words features are stored in the .feat files in each directory\n",
    "#text tokens are found in `[imdb.vocab]` and it states that a line with 0:7 in a .feat file\n",
    "#means that the first word in imdb.vocab (which is \"the\") appears 7 times in that review\n",
    "#this would be a way for counting the number of times certain words appear in a review\n",
    "#may be useful for finding a correlation between saying \"hate\" 5 or more times and them leaving a negative review.\n",
    "#it also included a file called `[imdbEr.txt]` which contains the expected rating for each token in the vocab file\n",
    "#states that its a good way to sense for the average polarity of a word in the dataset\n",
    "#maybe this would be a way to test our algorithms?\n",
    "\n",
    "#make sure we cite the dataset at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed222a95-963a-49e3-a2fe-a0438778eaec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text files found: 1000\n"
     ]
    }
   ],
   "source": [
    "#lets start with unsupervised learning so we can decide on what classifiers\n",
    "#or ensembles to use on the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "import requests\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import numpy as np\n",
    "\n",
    "api_url = \"https://api.github.com/repos/apmalani/cs-178-project/contents/train/unsup?ref=main\"\n",
    "base_raw = \"https://raw.githubusercontent.com/apmalani/cs-178-project/main/train/unsup/\"\n",
    "\n",
    "resp = requests.get(api_url)\n",
    "resp.raise_for_status()\n",
    "items = resp.json()\n",
    "\n",
    "txt_files = [item[\"name\"] for item in items if item[\"name\"].endswith(\".txt\")]\n",
    "print(f\"Text files found: {len(txt_files)}\")\n",
    "\n",
    "def fetch_file(idx_name):\n",
    "    idx, name = idx_name\n",
    "    url = base_raw + name\n",
    "    resp = requests.get(url)\n",
    "    resp.raise_for_status()\n",
    "    return idx, resp.text\n",
    "\n",
    "# Pre-allocate list, fixes the dict and list not matching\n",
    "Unlabeled_List = [None] * len(txt_files)\n",
    "Unlabeled_dict = {}\n",
    "\n",
    "with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "    futures = [executor.submit(fetch_file, (i, name)) for i, name in enumerate(txt_files)]\n",
    "    for future in futures:\n",
    "        idx, text = future.result()\n",
    "        Unlabeled_List[idx] = text\n",
    "        Unlabeled_dict[idx] = text\n",
    "\n",
    "# Now list[0] == dict[0]\n",
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc0a29ee-d196-4888-8648-1e9f7f0a7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I admit, the great majority of films released before say 1933 are just not for me. Of the dozen or so \"major\" silents I have viewed, one I loved (The Crowd), and two were very good (The Last Command and City Lights, that latter Chaplin circa 1931).<br /><br />So I was apprehensive about this one, and humor is often difficult to appreciate (uh, enjoy) decades later. I did like the lead actors, but thought little of the film.<br /><br />One intriguing sequence. Early on, the guys are supposed to get \"de-loused\" and for about three minutes, fully dressed, do some schtick. In the background, perhaps three dozen men pass by, all naked, white and black (WWI ?), and for most, their butts, part or full backside, are shown. Was this an early variation of beefcake courtesy of Howard Hughes?\n",
      "________________________\n",
      "I admit, the great majority of films released before say 1933 are just not for me. Of the dozen or so \"major\" silents I have viewed, one I loved (The Crowd), and two were very good (The Last Command and City Lights, that latter Chaplin circa 1931).<br /><br />So I was apprehensive about this one, and humor is often difficult to appreciate (uh, enjoy) decades later. I did like the lead actors, but thought little of the film.<br /><br />One intriguing sequence. Early on, the guys are supposed to get \"de-loused\" and for about three minutes, fully dressed, do some schtick. In the background, perhaps three dozen men pass by, all naked, white and black (WWI ?), and for most, their butts, part or full backside, are shown. Was this an early variation of beefcake courtesy of Howard Hughes?\n"
     ]
    }
   ],
   "source": [
    "#I decided to collect the data into two different data structures:\n",
    "print(Unlabeled_List[0])\n",
    "print(\"________________________\")\n",
    "print(Unlabeled_dict[0])\n",
    "#The list contains the same data that the dict will have but the dict uses integer\n",
    "#keys for each review, I thought this would be easier to use for something like a NN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8d3c43a-2358-45a0-a022-d3b34248ac9d",
   "metadata": {},
   "source": [
    "After running the above code the following should be true:\n",
    "\n",
    "The first 1000 (for now) unlabeled movie reviews are stored as text in \n",
    "Unlabeled_List <- a list that is 0 indexed\n",
    "Unlabeled_dict <- a dictionary where the keys are int indexes (0) and the values are the reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad5cc8",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d11b6",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1d00d",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
