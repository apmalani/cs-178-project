{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ff0a48e8",
   "metadata": {},
   "source": [
    "## CS 178 Project Code\n",
    "\n",
    "### Arun Malani, Brock Allan, Nathan Chau\n",
    "\n",
    "Includes data analysis, model training, performance charts, model fine-tuning, and brief explanations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9fefcb3a-cffb-4f13-ac56-c554676cb278",
   "metadata": {},
   "outputs": [],
   "source": [
    "#First of all we need to import the data that we are using, specifically the IMDB Review / Large Movie Review Dataset\n",
    "#Dataset\tType\t#Instances\t#Labels\t   Each Instance\t\n",
    "#NLP\t                50K    \t   2\t    Movie review\n",
    "\n",
    "#The dataset provides a set of 25,000 highly polar movie reviews for training, and 25,000 for testing, there is also unlabeled data - unsupervised?\n",
    "#States that Raw text and already processed bag of words formats are provided. See the README file contained in the release for more details.\n",
    "#Information gained from the readme is as follows:\n",
    "#25k positive and 25k negative reviews\n",
    "#50k unlabeled reviews for unsupervised learning\n",
    "#each movie has at most 30 reviews - since reviews for the same movie tend to have the same correlation\n",
    "#train and test sets are disjoint, so no significant performance by memorizing movie unique terms\n",
    "#negative reviews are those with a score <= 4 out of 10\n",
    "#positive reviews are those with a score >= 7 out of 10\n",
    "#labeled data sets do NOT have the neutral reviews 5-6 but unlabeled data sets DO\n",
    "#unsupervised learning therefore will want to have k = 3 clusters for each\n",
    "#states that for unlabeled data there are an even number of reviews > 5 and <= 5\n",
    "\n",
    "#contains the following file folders, train and test.\n",
    "#inside of these folders are a positive and negative folder\n",
    "#inside are reviews stored in text files named as follows:\n",
    "#`[[id]_[rating].txt]` where the id is a unique id and rating is the star rating for that review on a scale of 1-10.\n",
    "#for example: `[test/pos/200_8.txt]` is the text for a positive labeled test with id 200 and a rating of 8/10\n",
    "#the unlabeled set is in train and has a 0 for all ratings\n",
    "#the data includes the url for each review where the ID is actually the line in the file in which it occurs\n",
    "#for example: `[urls_[pos, neg, unsup].txt]` where ID 200 means line 200, the url however just goes to the movies review page\n",
    "\n",
    "#the already tokenized bag of words features are stored in the .feat files in each directory\n",
    "#text tokens are found in `[imdb.vocab]` and it states that a line with 0:7 in a .feat file\n",
    "#means that the first word in imdb.vocab (which is \"the\") appears 7 times in that review\n",
    "#this would be a way for counting the number of times certain words appear in a review\n",
    "#may be useful for finding a correlation between saying \"hate\" 5 or more times and them leaving a negative review.\n",
    "#it also included a file called `[imdbEr.txt]` which contains the expected rating for each token in the vocab file\n",
    "#states that its a good way to sense for the average polarity of a word in the dataset\n",
    "#maybe this would be a way to test our algorithms?\n",
    "\n",
    "#make sure we cite the dataset at some point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed222a95-963a-49e3-a2fe-a0438778eaec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets start with unsupervised learning so we can decide on what classifiers\n",
    "#or ensembles to use on the data\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.cluster import KMeans, AgglomerativeClustering\n",
    "from sklearn.inspection import DecisionBoundaryDisplay\n",
    "\n",
    "# Fix the random seed for reproducibility\n",
    "# !! Important !! : do not change this\n",
    "seed = 1234\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdad5cc8",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a44d11b6",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c1d00d",
   "metadata": {},
   "source": [
    "### Fine-tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
